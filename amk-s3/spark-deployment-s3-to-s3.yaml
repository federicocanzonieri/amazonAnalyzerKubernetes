apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    kompose.cmd: kompose convert -f docker-compose-new.yml
    kompose.version: 1.26.1 (a9d05d509)
  labels:
    io.kompose.service: spark
  name: spark
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: spark
  strategy: {}
  template:
    metadata:
      annotations:
        kompose.cmd: kompose convert -f docker-compose-new.yml
        kompose.version: 1.26.1 (a9d05d509)
      labels:
        io.kompose.network/tap: "true"
        io.kompose.service: spark
    spec:
      containers:
        - args:
            - ./bin/spark-submit --packages org.elasticsearch:elasticsearch-spark-30_2.12:7.12.1,org.apache.hadoop:hadoop-aws:3.2.0  /opt/tap/app.py
          env:
            - name: HOST_ELASTIC
              value: 10.0.100.51
            - name: INDEX
              value: reviews
            - name: PORT_ELASTIC
              value: "9200"
            - name: SPARK_ACTION
              value: spark-submit-python
            - name: TIMEOUT_BEFORE_START_SPARK
              value: "20"
            - name: TOPIC
              value: amazon
            - name: BUCKET_NAME
              valueFrom:
                secretKeyRef:
                  name: my-aws-credentials
                  key: BUCKET_NAME
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: my-aws-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: my-aws-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: BUCKET_OUTPUT
              valueFrom:
                secretKeyRef:
                  name: my-aws-credentials
                  key: BUCKET_OUTPUT
    
          image: federicocanzonieri/amk-spark-s3-to-s3 ##to opensearch
          name: spark-am
          resources: {}
      restartPolicy: Always
status: {}
